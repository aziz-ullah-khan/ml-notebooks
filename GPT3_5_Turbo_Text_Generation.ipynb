{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text generation using GPT 3.5 Turbo Model\n",
        "\n",
        "This notebook generate text by using GPT 3.5 turbo model"
      ],
      "metadata": {
        "id": "_bjGPep7W5ay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing rquired packages"
      ],
      "metadata": {
        "id": "cXbloE7ZXHmA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMLu-RjLWmTL"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing required packages"
      ],
      "metadata": {
        "id": "yHAKsyIKXQTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import pandas as pd\n",
        "import openai\n",
        "import json\n",
        "os.environ['OPENAI_API_KEY'] = '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'"
      ],
      "metadata": {
        "id": "RROijlX0XTTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data collection & Formating\n"
      ],
      "metadata": {
        "id": "opMH5-b3YyOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample input data\n",
        "data = [\n",
        "  {\"role\": \"system\", \"content\": \"You are a helpful assistant to generate text based on some input text\"},\n",
        "  {\"role\": \"user\", \"content\": \"You are a chatbot assistant powered by KYCport.com. Your response should be specific to the input.\"},\n",
        "  {\"role\": \"assistant\", \"content\": 'The tradition of writing didactic military handbooks stretched back to the fourth century BC; someeven considered that it began with Homer.'},\n",
        "  {\"role\": \"user\", \"content\": \"By Murray Dahm\"},\n",
        "  {\"role\": \"assistant\", \"content\": 'Nikephorosâ€™ text is 178 chapters long,compiled from classical and previous Byzantine authors'}\n",
        "]"
      ],
      "metadata": {
        "id": "ISatXuabXrgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training & Text Generation"
      ],
      "metadata": {
        "id": "cznhm9Z7Zavw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "V88XYd3EbGDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model=\"gpt-3.5-turbo\", data=[{\"role\": \"user\", \"content\": \"The Taktika of Nikephoros Ouranos\"}]):\n",
        "  # This function takes in GPT model and a dataset of messages as input and generates a text completion based on them\n",
        "  completion = openai.ChatCompletion.create(\n",
        "                                            model=model,  # The machine learning model to use for generating the text completion\n",
        "                                            messages=data  # The dataset of messages to use as context for generating the text completion\n",
        "                                            ) \n",
        "  # Returns the generated text from the GPT model\n",
        "  return completion['choices'][0]['message'].content\n"
      ],
      "metadata": {
        "id": "iC-1I0H9Zg3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code allows the user to have a conversation with a GPT model by entering text input\n",
        "print(\"Enter quit for closing the conversation\")\n",
        "\n",
        "while True:\n",
        "  # Prompt the user for input\n",
        "  user_text = input(\"user: \")\n",
        "  \n",
        "  # If the user types \"quit\", exit the conversation\n",
        "  if user_text == 'quit':\n",
        "    break\n",
        "    \n",
        "  # Format the user's input as a message to be used for generating the GPT model's response\n",
        "  turbo_format = {\"role\": \"user\", \"content\": user_text}\n",
        "  \n",
        "  # Add the formatted user message to the training data\n",
        "  data.append(turbo_format)\n",
        "  \n",
        "  # Generate a response from the GPT model using the updated training data\n",
        "  gpt_response = generate_text(\"gpt-3.5-turbo\", data)\n",
        "  \n",
        "  # Remove the formatted user message from the training data\n",
        "  data.pop()\n",
        "  \n",
        "  # Display the machine learning model's response\n",
        "  print(f'GPT Response: {gpt_response}')\n"
      ],
      "metadata": {
        "id": "sKR12LwLb5nW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}